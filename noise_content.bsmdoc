= Random Number
== Uniform Random Number
Most software package/library include function to generate uniform random number; but occasionally we may need to generate manually (e.g., to get a consist result on different platforms). One simple way is to use [https://en.wikipedia.org/wiki/Linear_congruential_generator| linear congruential generator]. Its general format is
$$
\begin{align}
x(n+1) = (a*x(n) + c) \mod m,
\end{align}
$$
where $a$, $c$ and $m$ are constant, and $x(n)$ is the last random number. There are many popular choices of these parameters; one implementation shown in \tag{b|man srand} looks like
{!highlight|c++|autogobble||{%
    static unsigned long next = 1;

    /* RAND_MAX assumed to be 32767 */
    int myrand(void) {
        next = next * 1103515245 + 12345;
        return((unsigned)(next/65536) % 32768);
    }

    void mysrand(unsigned int seed) {
        next = seed;
    }
%}!}

It will give you a pseudo random number between 0 and RAND_MAX. If you want to generate a random number between $L$ and $U$, you may follow the suggestion [https://eternallyconfuzzled.com/using-rand-c-c-advice-for-the-c-standard-librarys-rand-function/|here] if the following simple way doesn't give you good result.
{!highlight|c++|autogobble||{%
int r = L + myrand() * (U-L)/RAND_MAX;
%}!}

== Gaussian Random Number
Similarly, occasionally we may need to generate it by ourselves (e.g., on a embedded microcontroller).
[https:/en.wikipedia.org/wiki/Box%E2%80%93Muller_transform|Box-Muller] transform gives us an efficient way to generate random number with standard normal distribution from uniform distribution (Alternatively, I saw one uses central limit theorem to generate normal distribution samples by adding multiple samples from uniform distribution.). Suppose you have two independent samples from uniform distribution, then the following samples are from standard normal distribution,
$$
\begin{align}
x &= \sqrt{-2\ln{u_1}}\cos(2\pi u_2)\nonumber \\
y &= \sqrt{-2\ln{u_1}}\sin(2\pi u_2),
\end{align}
$$
where $u_1$, $u_2$ are from uniform distribution between 0 and 1, that is $u_1\sim U(0, 1)$.

To see why this is the case, let us first define
$$
\begin{align}
r = \sqrt{-2\ln{u_1}},
\end{align}
$$

The cumulative distribution function (CDF) of $r$ is defined as
$$
\begin{align}
P(r<R) &= P(\sqrt{-2\ln(u_1)}<R) \nonumber \\
&= P(u_1>e^{-\frac{R^2}{2}}) \nonumber\\
&= 1 - e^{-\frac{R^2}{2}}.
\end{align}
$$

Thus, its PDF is
$$
\begin{align}
f(R) &= \frac{\partial P(r<R)}{\partial R} \nonumber \\
&= R e^{-\frac{R^2}{2}}.
\end{align}
$$
This is the PDF for [https://en.wikipedia.org/wiki/Rayleigh_distribution|Rayleigh distribution].

Similarly, the PDF of $\theta = 2\pi u_2$ ($u_2\sim U(0, 1)$) is $\sim U(0, 2\pi)$.

Now, $x$, $y$ can be defined as
$$
\begin{align}
x &= r\cos(\theta),\nonumber \\
y &= r\sin(\theta).
\end{align}
$$
To get the joined PDF of $x$, $y$ (i.e., $f(x, y)$), first we need to calculate the Jacobian
$$
\begin{align}
\frac{\partial x, y}{\partial r, \theta} = \begin{bmatrix}
\cos(\theta) & -r\sin(\theta) \\
\sin(\theta) & r\cos(\theta) \\
\end{bmatrix}
 = r.
\end{align}
$$
Then, $f(x, y)$ can be written as
$$
\begin{align}
f(x, y) &= \frac{f(r, \theta)}{\frac{\partial x, y}{\partial r, \theta}} \nonumber \\
&= \frac{r}{2\pi}e^{-\frac{r^2}{2}}\times \frac{1}{r} \nonumber \\
&= \frac{1}{2\pi}e^{-\frac{x^2+y^2}{2}}.
\end{align}
$$
It is easy to see that $x$, $y$ are independent standard normal distribution.

#check the characteristic function of standard normal distribution.
#$$
#\begin{align}
#\phi(t) &= \int{e^{itx}f(x)dx} \nonumber\\
#        &= \frac{1}{2\pi}\int{e^{itx}e^{-\frac{x^2}{2}}dx} \nonumber\\
#        &= \frac{1}{2\pi}\int{e^{-\frac{x^2-2itx}{2}}dx} \nonumber\\
#        &= \frac{1}{2\pi}\int{e^{-\frac{x^2-2itx + (it)^2 - (it)^2}{2}}dx} \nonumber\\
#        &= \frac{1}{2\pi}\int{e^{-\frac{x^2-2itx + (it)^2 - (it)^2}{2}}dx} \nonumber\\
#        &= e^{-\frac{t^2}{2}}\frac{1}{2\pi}\int{e^{-\frac{(x-it)^2}{2}}dx} \nonumber\\
#        &= e^{-\frac{t^2}{2}}
#\end{align}
#$$
#
#Since characteristic function is unique for each distribution.
